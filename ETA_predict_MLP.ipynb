{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00868f6b-3a2e-488f-b8af-4941ae9cb49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e40ad47-eec5-4724-a75b-853ab44644d8",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677ecfb-305a-4a0c-a69e-be449288e432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46e490c-a43f-4476-ae92-fa064807bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e571c-f334-4d8b-accd-ce1117630b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613e4d30-c781-44fc-829d-d26e06953a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "output_folder_path = 'D:/A TESE/Modelo ML/CSV/voyages_final'  # Folder containing processed CSV files\n",
    "train_folder_path = 'D:/A TESE/Modelo ML/MLP/train_MLP/'  # Folder to save train files\n",
    "test_folder_path = 'D:/A TESE/Modelo ML/MLP/test_MLP/'  # Folder to save test files\n",
    "test_subfolder_path = os.path.join(test_folder_path, 'test/')  # Subfolder for test half\n",
    "validate_subfolder_path = os.path.join(test_folder_path, 'validate/')  # Subfolder for validation half\n",
    "\n",
    "# Create train, test, and validation folders if they don't exist\n",
    "os.makedirs(train_folder_path, exist_ok=True)\n",
    "os.makedirs(test_subfolder_path, exist_ok=True)\n",
    "os.makedirs(validate_subfolder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3c2e2-50c9-4a30-beab-6a073247387a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5132326e-721f-4730-8119-a8354810b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been split into train, test, and validate folders.\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files in the output folder\n",
    "all_files = [f for f in os.listdir(output_folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Shuffle files for random selection\n",
    "random.shuffle(all_files)\n",
    "\n",
    "# Split files into 70% train and 300% test\n",
    "train_files = all_files[:int(0.7 * len(all_files))]\n",
    "test_files = all_files[int(0.7 * len(all_files)):] \n",
    "\n",
    "# Move train files to train folder\n",
    "for file in train_files:\n",
    "    shutil.copy(os.path.join(output_folder_path, file), os.path.join(train_folder_path, file))\n",
    "\n",
    "# Split test files into test and validation halves\n",
    "for file in test_files:\n",
    "    file_path = os.path.join(output_folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Split data into two halves\n",
    "    midpoint = len(df) // 2\n",
    "    test_half = df.iloc[:midpoint]\n",
    "    validate_half = df.iloc[midpoint:]\n",
    "\n",
    "    # Save test half\n",
    "    test_half.to_csv(os.path.join(test_subfolder_path, file), index=False)\n",
    "\n",
    "    # Save validation half\n",
    "    validate_half.to_csv(os.path.join(validate_subfolder_path, file), index=False)\n",
    "\n",
    "print(\"Files have been split into train, test, and validate folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6da8e83-a05e-4f9f-8279-b8258a7b896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files created: 52\n"
     ]
    }
   ],
   "source": [
    "# Verifying the number of CSV files\n",
    "csv_files = [f for f in os.listdir(train_folder_path) if f.endswith('.csv')]\n",
    "csv_count = len(csv_files)\n",
    "\n",
    "print(f\"Total CSV files created: {csv_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734990d-8c29-41ab-bed4-ec74089f63ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655baeb7-763c-48a4-a434-8e946bbabd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R^2 Scores: [0.99700139 0.99675485 0.99932719 0.99791563 0.99686149]\n",
      "Mean Cross-Validation R^2: 0.9975721097939946\n",
      "Model MAE: 0.04022354000040902\n",
      "Model RMSE: 0.05796977816580805\n",
      "Model R^2: 0.9998257084795366\n",
      "Execution Time: 590.4941532611847 seconds\n",
      "ML model for KNN\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Load train data\n",
    "train_files = glob.glob(train_folder_path + \"*.csv\")\n",
    "train_data = pd.concat([pd.read_csv(f) for f in train_files], ignore_index=True)\n",
    "train_data.dropna(inplace=True)  # Drop rows with NaN values\n",
    "\n",
    "# Features and target variable\n",
    "X = train_data[['RTD', 'SOG', 'COG', 'LAT', 'LON']]  # Feature columns\n",
    "y = train_data['RTT']  # Target column\n",
    "\n",
    "# Split train data for validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Multi-Layer Perceptron Regressor model\n",
    "model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation to assess model performance\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-Validation R^2 Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation R^2: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Validate model\n",
    "y_pred = model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Model MAE: {mae}\")\n",
    "print(f\"Model RMSE: {rmse}\")\n",
    "print(f\"Model R^2: {r2}\")\n",
    "\n",
    "# Test the model on test data\n",
    "test_files = glob.glob(test_subfolder_path + \"*.csv\")\n",
    "for test_file in test_files:\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    test_data.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    X_test = test_data[['RTD', 'SOG', 'COG', 'LAT', 'LON']]  # Features\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Save the predictions to the corresponding validation file\n",
    "    validation_file = os.path.join(validate_subfolder_path, os.path.basename(test_file))\n",
    "    validation_data = pd.read_csv(validation_file)\n",
    "    validation_data = validation_data.iloc[:len(y_test_pred)]  # Ensure alignment if rows were dropped\n",
    "    validation_data['Predicted_RTT'] = y_test_pred\n",
    "\n",
    "    # Ensure 'BaseDateTime' is a datetime object\n",
    "    validation_data['BaseDateTime'] = pd.to_datetime(validation_data['BaseDateTime'], errors='coerce')\n",
    "\n",
    "    # Calculate Predicted_ETA by adding Predicted_RTT (in hours) to BaseDateTime\n",
    "    validation_data['Predicted_ETA'] = validation_data['BaseDateTime'] + pd.to_timedelta(validation_data['Predicted_RTT'], unit='h')\n",
    "\n",
    "    # Ensure Predicted_ETA is displayed properly as datetime\n",
    "    validation_data['Predicted_ETA'] = validation_data['Predicted_ETA'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Save the updated validation file with the correct datetime format\n",
    "    validation_data.to_csv(validation_file, index=False)\n",
    "\n",
    "# End the timer and print execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution Time: {execution_time} seconds\")\n",
    "print(\"ML model for MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea3bd6-71dc-4bde-8a3f-f71125c4df2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd943c38-f8f7-473c-95e6-165dadd09303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30ec84-72d2-427a-b6dc-940eca44a79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9559e73d-cb1f-48aa-ab15-6a3349abae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R^2 Scores: [0.99929535 0.99960151 0.9934705  0.99785575 0.99049837]\n",
      "Mean Cross-Validation R^2: 0.9961442967207583\n",
      "Model MAE: 0.052642131015235565\n",
      "Model RMSE: 0.08001001712137595\n",
      "Model R^2: 0.9996893008523722\n",
      "ML model for MLP\n",
      "Model predictions have been saved to the validation files.\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "train_files = glob.glob(train_folder_path + \"*.csv\")\n",
    "train_data = pd.concat([pd.read_csv(f) for f in train_files], ignore_index=True)\n",
    "train_data.dropna(inplace=True)  # Drop rows with NaN values\n",
    "\n",
    "# Features and target variable\n",
    "X = train_data[['RTD', 'SOG', 'COG','LAT','LON']]  # Feature columns (added 'COG')\n",
    "y = train_data['RTT']  # Target column\n",
    "\n",
    "# Split train data for validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Multi-Layer Perceptron Regressor model\n",
    "model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation to assess model performance\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-Validation R^2 Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation R^2: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Validate model\n",
    "y_pred = model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "print(f\"Model MAE: {mae}\")\n",
    "print(f\"Model RMSE: {rmse}\")\n",
    "print(f\"Model R^2: {r2}\")\n",
    "\n",
    "# Test the model on test data\n",
    "test_files = glob.glob(test_subfolder_path + \"*.csv\")\n",
    "for test_file in test_files:\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    test_data.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    X_test = test_data[['RTD', 'SOG', 'COG','LAT','LON']]  # Updated features\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Save the predictions to the corresponding validation file\n",
    "    validation_file = os.path.join(validate_subfolder_path, os.path.basename(test_file))\n",
    "    validation_data = pd.read_csv(validation_file)\n",
    "    validation_data = validation_data.iloc[:len(y_test_pred)]  # Ensure alignment if rows were dropped\n",
    "    validation_data['Predicted_RTT'] = y_test_pred\n",
    "    validation_data.to_csv(validation_file, index=False)\n",
    "print(\"ML model for MLP\")\n",
    "print(\"Model predictions have been saved to the validation files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d4978-53bc-4041-9a39-76d453901c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
